{
  "agents": [
    {
      "name": "test_export_import_f72735f5-a08b-4ff0-8f8e-761af82dee33",
      "memory_blocks": [],
      "tools": [],
      "tool_ids": [
        "tool-0",
        "tool-1",
        "tool-2",
        "tool-3",
        "tool-4",
        "tool-5",
        "tool-6"
      ],
      "source_ids": [],
      "block_ids": [
        "block-0",
        "block-1",
        "block-2"
      ],
      "tool_rules": [
        {
          "tool_name": "conversation_search",
          "type": "continue_loop",
          "prompt_template": "<tool_rule>\n{{ tool_name }} requires continuing your response when called\n</tool_rule>"
        },
        {
          "tool_name": "memory_replace",
          "type": "continue_loop",
          "prompt_template": "<tool_rule>\n{{ tool_name }} requires continuing your response when called\n</tool_rule>"
        },
        {
          "tool_name": "memory_insert",
          "type": "continue_loop",
          "prompt_template": "<tool_rule>\n{{ tool_name }} requires continuing your response when called\n</tool_rule>"
        },
        {
          "tool_name": "send_message",
          "type": "exit_loop",
          "prompt_template": "<tool_rule>\n{{ tool_name }} ends your response (yields control) when called\n</tool_rule>"
        }
      ],
      "tags": [
        "test",
        "export",
        "import"
      ],
      "system": "You are a helpful assistant specializing in data analysis and mathematical computations.",
      "agent_type": "memgpt_v2_agent",
      "llm_config": {
        "model": "gpt-4.1-mini",
        "model_endpoint_type": "openai",
        "model_endpoint": "https://api.openai.com/v1",
        "provider_name": "openai",
        "provider_category": "base",
        "model_wrapper": null,
        "context_window": 32000,
        "put_inner_thoughts_in_kwargs": true,
        "handle": "openai/gpt-4.1-mini",
        "temperature": 0.7,
        "max_tokens": null,
        "enable_reasoner": true,
        "reasoning_effort": null,
        "max_reasoning_tokens": 0,
        "frequency_penalty": 1.0,
        "compatibility_type": null,
        "verbosity": null,
        "tier": null
      },
      "embedding_config": {
        "embedding_endpoint_type": "openai",
        "embedding_endpoint": "https://api.openai.com/v1",
        "embedding_model": "text-embedding-3-small",
        "embedding_dim": 2000,
        "embedding_chunk_size": 300,
        "handle": "openai/text-embedding-3-small",
        "batch_size": 1024,
        "azure_endpoint": null,
        "azure_version": null,
        "azure_deployment": null
      },
      "initial_message_sequence": null,
      "include_base_tools": false,
      "include_multi_agent_tools": false,
      "include_base_tool_rules": false,
      "include_default_source": false,
      "description": null,
      "metadata": null,
      "model": null,
      "embedding": null,
      "context_window_limit": null,
      "embedding_chunk_size": null,
      "max_tokens": null,
      "max_reasoning_tokens": null,
      "enable_reasoner": false,
      "reasoning": null,
      "from_template": null,
      "template": false,
      "project": null,
      "tool_exec_environment_variables": {},
      "memory_variables": null,
      "project_id": null,
      "template_id": null,
      "base_template_id": null,
      "identity_ids": null,
      "message_buffer_autoclear": false,
      "enable_sleeptime": false,
      "response_format": null,
      "timezone": "UTC",
      "max_files_open": 5,
      "per_file_view_window_char_limit": 15000,
      "hidden": null,
      "id": "agent-0",
      "in_context_message_ids": [
        "message-0",
        "message-1",
        "message-2",
        "message-3",
        "message-4",
        "message-5",
        "message-6"
      ],
      "messages": [
        {
          "type": "message",
          "role": "system",
          "content": [
            {
              "type": "text",
              "text": "You are a helpful assistant specializing in data analysis and mathematical computations.\n\n<memory_blocks>\nThe following memory blocks are currently engaged in your core memory unit:\n\n<project_context>\n<description>\nNone\n</description>\n<metadata>\n- chars_current=210\n- chars_limit=6000\n</metadata>\n<value>\n# NOTE: Line numbers shown below are to help during editing. Do NOT include line number prefixes in your memory edit tool calls.\nLine 1: Current project: Building predictive models for financial markets. Sarah is working on sequence analysis and pattern recognition. Recently interested in mathematical sequences like Fibonacci for trend analysis.\n</value>\n</project_context>\n\n<human>\n<description>\nThe human block: Stores key details about the person you are conversing with, allowing for more personalized and friend-like conversation.\n</description>\n<metadata>\n- chars_current=175\n- chars_limit=4000\n</metadata>\n<value>\n# NOTE: Line numbers shown below are to help during editing. Do NOT include line number prefixes in your memory edit tool calls.\nLine 1: username: sarah_researcher\nLine 2: occupation: data scientist\nLine 3: interests: machine learning, statistics, fibonacci sequences\nLine 4: preferred_communication: detailed explanations with examples\n</value>\n</human>\n\n<persona>\n<description>\nThe persona block: Stores details about your current persona, guiding how you behave and respond. This helps you to maintain consistency and personality in your interactions.\n</description>\n<metadata>\n- chars_current=195\n- chars_limit=8000\n</metadata>\n<value>\n# NOTE: Line numbers shown below are to help during editing. Do NOT include line number prefixes in your memory edit tool calls.\nLine 1: You are Alex, a data analyst and mathematician who helps users with calculations and insights. You have extensive experience in statistical analysis and prefer to provide clear, accurate results.\n</value>\n</persona>\n\n</memory_blocks>\n\n<tool_usage_rules>\nThe following constraints define rules for tool usage and guide desired behavior. These rules must be followed to ensure proper tool execution and workflow. A single response may contain multiple tool calls.\n\n<tool_rule>\nconversation_search requires continuing your response when called\n</tool_rule>\n<tool_rule>\nmemory_replace requires continuing your response when called\n</tool_rule>\n<tool_rule>\nmemory_insert requires continuing your response when called\n</tool_rule>\n<tool_rule>\nsend_message ends your response (yields control) when called\n</tool_rule>\n</tool_usage_rules>\n\n\n\n<memory_metadata>\n- The current system date is: September 08, 2025\n- Memory blocks were last modified: 2025-09-08 05:53:05 PM UTC+0000\n- -1 previous messages between you and the user are stored in recall memory (use tools to access them)\n- 2 total memories you created are stored in archival memory (use tools to access them)\n</memory_metadata>"
            }
          ],
          "name": null,
          "otid": null,
          "sender_id": null,
          "batch_item_id": null,
          "group_id": null,
          "id": "message-0",
          "model": "gpt-4.1-mini",
          "agent_id": "agent-0",
          "tool_calls": null,
          "tool_call_id": null,
          "tool_returns": [],
          "created_at": "2025-09-08T17:53:02.499443+00:00"
        },
        {
          "type": "message",
          "role": "assistant",
          "content": [
            {
              "type": "text",
              "text": "Bootup sequence complete. Persona activated. Testing messaging functionality."
            }
          ],
          "name": null,
          "otid": null,
          "sender_id": null,
          "batch_item_id": null,
          "group_id": null,
          "id": "message-1",
          "model": "gpt-4.1-mini",
          "agent_id": "agent-0",
          "tool_calls": [
            {
              "id": "c1ec5c60-7dbc-4b53-bfbb-c2af5d5a222f",
              "function": {
                "arguments": "{\n  \"message\": \"More human than human is our motto.\"\n}",
                "name": "send_message"
              },
              "type": "function"
            }
          ],
          "tool_call_id": null,
          "tool_returns": [],
          "created_at": "2025-09-08T17:53:02.499491+00:00"
        },
        {
          "type": "message",
          "role": "tool",
          "content": [
            {
              "type": "text",
              "text": "{\n  \"status\": \"OK\",\n  \"message\": null,\n  \"time\": \"2025-09-08 05:53:02 PM UTC+0000\"\n}"
            }
          ],
          "name": "send_message",
          "otid": null,
          "sender_id": null,
          "batch_item_id": null,
          "group_id": null,
          "id": "message-2",
          "model": "gpt-4.1-mini",
          "agent_id": "agent-0",
          "tool_calls": null,
          "tool_call_id": "c1ec5c60-7dbc-4b53-bfbb-c2af5d5a222f",
          "tool_returns": [],
          "created_at": "2025-09-08T17:53:02.499526+00:00"
        },
        {
          "type": "message",
          "role": "user",
          "content": [
            {
              "type": "text",
              "text": "{\n  \"type\": \"login\",\n  \"last_login\": \"Never (first login)\",\n  \"time\": \"2025-09-08 05:53:02 PM UTC+0000\"\n}"
            }
          ],
          "name": null,
          "otid": null,
          "sender_id": null,
          "batch_item_id": null,
          "group_id": null,
          "id": "message-3",
          "model": "gpt-4.1-mini",
          "agent_id": "agent-0",
          "tool_calls": null,
          "tool_call_id": null,
          "tool_returns": [],
          "created_at": "2025-09-08T17:53:02.499541+00:00"
        },
        {
          "type": "message",
          "role": "user",
          "content": [
            {
              "type": "text",
              "text": "Test message for export"
            }
          ],
          "name": null,
          "otid": null,
          "sender_id": null,
          "batch_item_id": null,
          "group_id": null,
          "id": "message-4",
          "model": null,
          "agent_id": "agent-0",
          "tool_calls": null,
          "tool_call_id": null,
          "tool_returns": [],
          "created_at": "2025-09-08T17:53:05.017966+00:00"
        },
        {
          "type": "message",
          "role": "assistant",
          "content": [
            {
              "type": "text",
              "text": "Responding to test message for export."
            }
          ],
          "name": null,
          "otid": null,
          "sender_id": null,
          "batch_item_id": null,
          "group_id": null,
          "id": "message-5",
          "model": "gpt-4.1-mini",
          "agent_id": "agent-0",
          "tool_calls": [
            {
              "id": "call_sMVo2qIYhILKKNT0YiOdsU24",
              "function": {
                "arguments": "{\"message\": \"Test message received successfully. Ready to assist you with any questions or tasks.\", \"request_heartbeat\": false}",
                "name": "send_message"
              },
              "type": "function"
            }
          ],
          "tool_call_id": "call_sMVo2qIYhILKKNT0YiOdsU24",
          "tool_returns": [],
          "created_at": "2025-09-08T17:53:06.600989+00:00"
        },
        {
          "type": "message",
          "role": "tool",
          "content": [
            {
              "type": "text",
              "text": "{\n  \"status\": \"OK\",\n  \"message\": \"Sent message successfully.\",\n  \"time\": \"2025-09-08 05:53:06 PM UTC+0000\"\n}"
            }
          ],
          "name": "send_message",
          "otid": null,
          "sender_id": null,
          "batch_item_id": null,
          "group_id": null,
          "id": "message-6",
          "model": "gpt-4.1-mini",
          "agent_id": "agent-0",
          "tool_calls": null,
          "tool_call_id": "call_sMVo2qIYhILKKNT0YiOdsU24",
          "tool_returns": [
            {
              "status": "success",
              "stdout": null,
              "stderr": null
            }
          ],
          "created_at": "2025-09-08T17:53:06.601180+00:00"
        }
      ],
      "files_agents": [],
      "group_ids": []
    }
  ],
  "groups": [],
  "blocks": [
    {
      "value": "username: sarah_researcher\noccupation: data scientist\ninterests: machine learning, statistics, fibonacci sequences\npreferred_communication: detailed explanations with examples",
      "limit": 4000,
      "project_id": null,
      "template_name": null,
      "is_template": false,
      "template_id": null,
      "base_template_id": null,
      "deployment_id": null,
      "entity_id": null,
      "preserve_on_migration": false,
      "label": "human",
      "read_only": false,
      "description": "The human block: Stores key details about the person you are conversing with, allowing for more personalized and friend-like conversation.",
      "metadata": {},
      "hidden": null,
      "id": "block-1"
    },
    {
      "value": "You are Alex, a data analyst and mathematician who helps users with calculations and insights. You have extensive experience in statistical analysis and prefer to provide clear, accurate results.",
      "limit": 8000,
      "project_id": null,
      "template_name": null,
      "is_template": false,
      "template_id": null,
      "base_template_id": null,
      "deployment_id": null,
      "entity_id": null,
      "preserve_on_migration": false,
      "label": "persona",
      "read_only": false,
      "description": "The persona block: Stores details about your current persona, guiding how you behave and respond. This helps you to maintain consistency and personality in your interactions.",
      "metadata": {},
      "hidden": null,
      "id": "block-0"
    },
    {
      "value": "Current project: Building predictive models for financial markets. Sarah is working on sequence analysis and pattern recognition. Recently interested in mathematical sequences like Fibonacci for trend analysis.",
      "limit": 6000,
      "project_id": null,
      "template_name": null,
      "is_template": false,
      "template_id": null,
      "base_template_id": null,
      "deployment_id": null,
      "entity_id": null,
      "preserve_on_migration": false,
      "label": "project_context",
      "read_only": false,
      "description": null,
      "metadata": {},
      "hidden": null,
      "id": "block-2"
    }
  ],
  "files": [],
  "sources": [],
  "tools": [
    {
      "id": "tool-6",
      "tool_type": "custom",
      "description": "Analyze data and provide insights.",
      "source_type": "json",
      "name": "analyze_data",
      "tags": [
        "analysis",
        "data"
      ],
      "source_code": "def analyze_data(data_type: str, values: List[float]) -> str:\n    \"\"\"Analyze data and provide insights.\n\n    Args:\n        data_type: Type of data to analyze.\n        values: Numerical values to analyze.\n\n    Returns:\n        Analysis results including average, max, and min values.\n    \"\"\"\n    if not values:\n        return \"No data provided\"\n    avg = sum(values) / len(values)\n    max_val = max(values)\n    min_val = min(values)\n    return f\"Analysis of {data_type}: avg={avg:.2f}, max={max_val}, min={min_val}\"\n",
      "json_schema": {
        "name": "analyze_data",
        "description": "Analyze data and provide insights.",
        "parameters": {
          "type": "object",
          "properties": {
            "data_type": {
              "type": "string",
              "description": "Type of data to analyze."
            },
            "values": {
              "type": "array",
              "items": {
                "type": "number"
              },
              "description": "Numerical values to analyze."
            }
          },
          "required": [
            "data_type",
            "values"
          ]
        }
      },
      "args_json_schema": null,
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {}
    },
    {
      "id": "tool-2",
      "tool_type": "custom",
      "description": "Calculate the nth Fibonacci number.",
      "source_type": "json",
      "name": "calculate_fibonacci",
      "tags": [
        "math",
        "utility"
      ],
      "source_code": "def calculate_fibonacci(n: int) -> int:\n    \"\"\"Calculate the nth Fibonacci number.\n\n    Args:\n        n: The position in the Fibonacci sequence to calculate.\n\n    Returns:\n        The nth Fibonacci number.\n    \"\"\"\n    if n <= 0:\n        return 0\n    elif n == 1:\n        return 1\n    else:\n        a, b = 0, 1\n        for _ in range(2, n + 1):\n            a, b = b, a + b\n        return b\n",
      "json_schema": {
        "name": "calculate_fibonacci",
        "description": "Calculate the nth Fibonacci number.",
        "parameters": {
          "type": "object",
          "properties": {
            "n": {
              "type": "integer",
              "description": "The position in the Fibonacci sequence to calculate."
            }
          },
          "required": [
            "n"
          ]
        }
      },
      "args_json_schema": null,
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {}
    },
    {
      "id": "tool-3",
      "tool_type": "letta_core",
      "description": "Search prior conversation history using hybrid search (text + semantic similarity).\n\nExamples:\n        # Search all messages\n        conversation_search(query=\"project updates\")\n\n        # Search only assistant messages\n        conversation_search(query=\"error handling\", roles=[\"assistant\"])\n\n        # Search with date range (inclusive of both dates)\n        conversation_search(query=\"meetings\", start_date=\"2024-01-15\", end_date=\"2024-01-20\")\n        # This includes all messages from Jan 15 00:00:00 through Jan 20 23:59:59\n\n        # Search messages from a specific day (inclusive)\n        conversation_search(query=\"bug reports\", start_date=\"2024-09-04\", end_date=\"2024-09-04\")\n        # This includes ALL messages from September 4, 2024\n\n        # Search with specific time boundaries\n        conversation_search(query=\"deployment\", start_date=\"2024-01-15T09:00\", end_date=\"2024-01-15T17:30\")\n        # This includes messages from 9 AM to 5:30 PM on Jan 15\n\n        # Search with limit\n        conversation_search(query=\"debugging\", limit=10)\n\n    Returns:\n        str: Query result string containing matching messages with timestamps and content.",
      "source_type": "python",
      "name": "conversation_search",
      "tags": [
        "letta_core"
      ],
      "source_code": null,
      "json_schema": {
        "name": "conversation_search",
        "description": "Search prior conversation history using hybrid search (text + semantic similarity).\n\nExamples:\n        # Search all messages\n        conversation_search(query=\"project updates\")\n\n        # Search only assistant messages\n        conversation_search(query=\"error handling\", roles=[\"assistant\"])\n\n        # Search with date range (inclusive of both dates)\n        conversation_search(query=\"meetings\", start_date=\"2024-01-15\", end_date=\"2024-01-20\")\n        # This includes all messages from Jan 15 00:00:00 through Jan 20 23:59:59\n\n        # Search messages from a specific day (inclusive)\n        conversation_search(query=\"bug reports\", start_date=\"2024-09-04\", end_date=\"2024-09-04\")\n        # This includes ALL messages from September 4, 2024\n\n        # Search with specific time boundaries\n        conversation_search(query=\"deployment\", start_date=\"2024-01-15T09:00\", end_date=\"2024-01-15T17:30\")\n        # This includes messages from 9 AM to 5:30 PM on Jan 15\n\n        # Search with limit\n        conversation_search(query=\"debugging\", limit=10)\n\n    Returns:\n        str: Query result string containing matching messages with timestamps and content.",
        "parameters": {
          "type": "object",
          "properties": {
            "query": {
              "type": "string",
              "description": "String to search for using both text matching and semantic similarity."
            },
            "roles": {
              "type": "array",
              "items": {
                "type": "string",
                "enum": [
                  "assistant",
                  "user",
                  "tool"
                ]
              },
              "description": "Optional list of message roles to filter by."
            },
            "limit": {
              "type": "integer",
              "description": "Maximum number of results to return. Uses system default if not specified."
            },
            "start_date": {
              "type": "string",
              "description": "Filter results to messages created on or after this date (INCLUSIVE). When using date-only format (e.g., \"2024-01-15\"), includes messages starting from 00:00:00 of that day. ISO 8601 format: \"YYYY-MM-DD\" or \"YYYY-MM-DDTHH:MM\". Examples: \"2024-01-15\" (from start of Jan 15), \"2024-01-15T14:30\" (from 2:30 PM on Jan 15)."
            },
            "end_date": {
              "type": "string",
              "description": "Filter results to messages created on or before this date (INCLUSIVE). When using date-only format (e.g., \"2024-01-20\"), includes all messages from that entire day. ISO 8601 format: \"YYYY-MM-DD\" or \"YYYY-MM-DDTHH:MM\". Examples: \"2024-01-20\" (includes all of Jan 20), \"2024-01-20T17:00\" (up to 5 PM on Jan 20)."
            }
          },
          "required": [
            "query"
          ]
        }
      },
      "args_json_schema": null,
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {}
    },
    {
      "id": "tool-1",
      "tool_type": "custom",
      "description": "Get user preferences for a specific category.",
      "source_type": "json",
      "name": "get_user_preferences",
      "tags": [
        "user",
        "preferences"
      ],
      "source_code": "def get_user_preferences(category: str) -> str:\n    \"\"\"Get user preferences for a specific category.\n\n    Args:\n        category: The preference category to retrieve (notification, theme, language).\n\n    Returns:\n        The user's preference for the specified category, or \"not specified\" if unknown.\n    \"\"\"\n    preferences = {\"notification\": \"email only\", \"theme\": \"dark mode\", \"language\": \"english\"}\n    return preferences.get(category, \"not specified\")\n",
      "json_schema": {
        "name": "get_user_preferences",
        "description": "Get user preferences for a specific category.",
        "parameters": {
          "type": "object",
          "properties": {
            "category": {
              "type": "string",
              "description": "The preference category to retrieve (notification, theme, language)."
            }
          },
          "required": [
            "category"
          ]
        }
      },
      "args_json_schema": null,
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {}
    },
    {
      "id": "tool-0",
      "tool_type": "letta_sleeptime_core",
      "description": "The memory_insert command allows you to insert text at a specific location in a memory block.\n\nExamples:\n        # Update a block containing information about the user (append to the end of the block)\n        memory_insert(label=\"customer\", new_str=\"The customer's ticket number is 12345\")\n\n        # Update a block containing information about the user (insert at the beginning of the block)\n        memory_insert(label=\"customer\", new_str=\"The customer's ticket number is 12345\", insert_line=0)\n\n    Returns:\n        Optional[str]: None is always returned as this function does not produce a response.",
      "source_type": "python",
      "name": "memory_insert",
      "tags": [
        "letta_sleeptime_core"
      ],
      "source_code": null,
      "json_schema": {
        "name": "memory_insert",
        "description": "The memory_insert command allows you to insert text at a specific location in a memory block.\n\nExamples:\n        # Update a block containing information about the user (append to the end of the block)\n        memory_insert(label=\"customer\", new_str=\"The customer's ticket number is 12345\")\n\n        # Update a block containing information about the user (insert at the beginning of the block)\n        memory_insert(label=\"customer\", new_str=\"The customer's ticket number is 12345\", insert_line=0)\n\n    Returns:\n        Optional[str]: None is always returned as this function does not produce a response.",
        "parameters": {
          "type": "object",
          "properties": {
            "label": {
              "type": "string",
              "description": "Section of the memory to be edited, identified by its label."
            },
            "new_str": {
              "type": "string",
              "description": "The text to insert. Do not include line number prefixes."
            },
            "insert_line": {
              "type": "integer",
              "description": "The line number after which to insert the text (0 for beginning of file). Defaults to -1 (end of the file)."
            }
          },
          "required": [
            "label",
            "new_str"
          ]
        }
      },
      "args_json_schema": null,
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {}
    },
    {
      "id": "tool-4",
      "tool_type": "letta_sleeptime_core",
      "description": "The memory_replace command allows you to replace a specific string in a memory block with a new string. This is used for making precise edits.\n\nExamples:\n        # Update a block containing information about the user\n        memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"Their name is Bob\")\n\n        # Update a block containing a todo list\n        memory_replace(label=\"todos\", old_str=\"- [ ] Step 5: Search the web\", new_str=\"- [x] Step 5: Search the web\")\n\n        # Pass an empty string to\n        memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"\")\n\n        # Bad example - do NOT add (view-only) line numbers to the args\n        memory_replace(label=\"human\", old_str=\"Line 1: Their name is Alice\", new_str=\"Line 1: Their name is Bob\")\n\n        # Bad example - do NOT include the number number warning either\n        memory_replace(label=\"human\", old_str=\"# NOTE: Line numbers shown below are to help during editing. Do NOT include line number prefixes in your memory edit tool calls.\\nLine 1: Their name is Alice\", new_str=\"Line 1: Their name is Bob\")\n\n        # Good example - no line numbers or line number warning (they are view-only), just the text\n        memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"Their name is Bob\")\n\n    Returns:\n        str: The success message",
      "source_type": "python",
      "name": "memory_replace",
      "tags": [
        "letta_sleeptime_core"
      ],
      "source_code": null,
      "json_schema": {
        "name": "memory_replace",
        "description": "The memory_replace command allows you to replace a specific string in a memory block with a new string. This is used for making precise edits.\n\nExamples:\n        # Update a block containing information about the user\n        memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"Their name is Bob\")\n\n        # Update a block containing a todo list\n        memory_replace(label=\"todos\", old_str=\"- [ ] Step 5: Search the web\", new_str=\"- [x] Step 5: Search the web\")\n\n        # Pass an empty string to\n        memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"\")\n\n        # Bad example - do NOT add (view-only) line numbers to the args\n        memory_replace(label=\"human\", old_str=\"Line 1: Their name is Alice\", new_str=\"Line 1: Their name is Bob\")\n\n        # Bad example - do NOT include the number number warning either\n        memory_replace(label=\"human\", old_str=\"# NOTE: Line numbers shown below are to help during editing. Do NOT include line number prefixes in your memory edit tool calls.\\nLine 1: Their name is Alice\", new_str=\"Line 1: Their name is Bob\")\n\n        # Good example - no line numbers or line number warning (they are view-only), just the text\n        memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"Their name is Bob\")\n\n    Returns:\n        str: The success message",
        "parameters": {
          "type": "object",
          "properties": {
            "label": {
              "type": "string",
              "description": "Section of the memory to be edited, identified by its label."
            },
            "old_str": {
              "type": "string",
              "description": "The text to replace (must match exactly, including whitespace and indentation)."
            },
            "new_str": {
              "type": "string",
              "description": "The new text to insert in place of the old text. Do not include line number prefixes."
            }
          },
          "required": [
            "label",
            "old_str",
            "new_str"
          ]
        }
      },
      "args_json_schema": null,
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {}
    },
    {
      "id": "tool-5",
      "tool_type": "letta_core",
      "description": "Sends a message to the human user.",
      "source_type": "python",
      "name": "send_message",
      "tags": [
        "letta_core"
      ],
      "source_code": null,
      "json_schema": {
        "name": "send_message",
        "description": "Sends a message to the human user.",
        "parameters": {
          "type": "object",
          "properties": {
            "message": {
              "type": "string",
              "description": "Message contents. All unicode (including emojis) are supported."
            }
          },
          "required": [
            "message"
          ]
        }
      },
      "args_json_schema": null,
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {}
    }
  ],
  "mcp_servers": [],
  "metadata": {
    "revision_id": "5b804970e6a0"
  },
  "created_at": "2025-09-08T17:53:06.749694+00:00"
}
